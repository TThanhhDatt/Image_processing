# -*- coding: utf-8 -*-
"""Final_DIP_Test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jScF8xHCSRizkYmedKYHCRvHO4iybnOt
"""

# Import modules
import cv2
import numpy as np

# Support Function
def estimate_red_color(roi):
  ''' Ham xac dinh ti le mau do '''
  # Convert the roi to hsv
  hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
  lower_red1 = np.array([0, 50, 50])
  upper_red1 = np.array([10, 255, 255])
  mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
  lower_red2 = np.array([170, 50, 50])
  upper_red2 = np.array([180, 255, 255])
  mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
  mask_red = mask1 + mask2

  # Create a mask for blue regions
  red_area = cv2.countNonZero(mask_red)
  roi_area = roi.shape[0] * roi.shape[1]

  # Check if blue area covers a significant portion of the ROI
  if red_area / roi_area > 0.4:
    return True
  return False

def estimate_blue_color(roi):
  ''' Ham xac dinh ti le mau xanh '''
  hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
  # Define blue color range (for the background inside the sign)
  lower_blue = np.array([100, 150, 50])
  upper_blue = np.array([140, 255, 255])

  # Create a mask for blue regions
  blue_mask = cv2.inRange(hsv_roi, lower_blue, upper_blue)
  blue_area = cv2.countNonZero(blue_mask)

    # Check if blue area covers a significant portion of the ROI
  roi_area = roi.shape[0] * roi.shape[1]
  if 0.25 < blue_area / roi_area < 0.3:
      return True
  return False

def estimate_color_keep_right(roi):
  ''' Ham xac dinh ti le mau vang '''
  hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
  # Define blue color range (for the background inside the sign)
  lower_yellow = np.array([20, 100, 100])
  upper_yellow = np.array([30, 255, 255])
    # Create a mask for blue regions
  yl_mask = cv2.inRange(hsv_roi, lower_yellow, lower_yellow)
  yl_area = cv2.countNonZero(yl_mask)

    # Check if blue area covers a significant portion of the ROI
  roi_area = roi.shape[0] * roi.shape[1]
  if yl_area / roi_area < 0.2:
      return True
  return False

def detect_keep_right(image):
  ''' Ham xac dinh bien bao huong phai di thang '''
  # Convert the image to grayscale
  hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
  # Set up mask for traffic sign with red and blue color
  lower_blue = np.array([100, 150, 50])
  upper_blue = np.array([140, 255, 255])
  mask = cv2.inRange(hsv, lower_blue, upper_blue)
  # Smooth image and noise reduction
  blur = cv2.GaussianBlur(mask, (5, 5), 0)

  # Detect edges
  edges = cv2.Canny(blur, 50, 150)
  contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

  # Loop through contours to find potential signs
  for cnt in contours:
    peri = cv2.arcLength(cnt, True)
    approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)
    if len(approx) > 4:
      (x,y), radius = cv2.minEnclosingCircle(cnt)
      center = (int(x), int(y))
      radius = int(radius)
      contour_area = cv2.contourArea(cnt)
      bounding_box_area = (2 * radius) ** 2
      area_ratio = contour_area / bounding_box_area
      # Filter contours based on size and shape
      if 0.6 < area_ratio < 2.0 and radius > 25 and radius < 60:
        y1 = max(0, int(y - radius))
        y2 = min(image.shape[0], int(y + radius))
        x1 = max(0, int(x - radius))
        x2 = min(image.shape[1], int(x + radius))

        roi = image[y1:y2, x1:x2]
        roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        roi_edges = cv2.Canny(roi_gray, 50, 150)
        contours_1, _1 = cv2.findContours(roi_edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours_1:
          epsilon = 0.02 * cv2.arcLength(contour, True)
          approx_1 = cv2.approxPolyDP(contour, epsilon, True)
          # Check for heptagon shape
          if len(approx_1) ==7 and estimate_color_keep_right(roi):
            cv2.rectangle(image, (int(x - radius), int(y - radius)), (int(x + radius), int(y + radius)), (0, 255, 0), 2)
            cv2.putText(image, "HUONG PHAI DI VONG", (int(x), int(y + radius)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

def detect_one_way(image):
  ''' Ham xac dinh bien bao cam di nguoc chieu '''
  # Convert the image to hsv
  hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
  # Set up mask for traffic sign with red color
  lower_red1 = np.array([0, 50, 50])
  upper_red1 = np.array([10, 255, 255])
  mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
  lower_red2 = np.array([170, 50, 50])
  upper_red2 = np.array([180, 255, 255])
  mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
  mask = mask1 + mask2
  blur = cv2.GaussianBlur(mask, (5, 5), 0)
  # Detect edges
  edges = cv2.Canny(blur, 50, 150)
  contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

  for cnt in contours:
    peri = cv2.arcLength(cnt, True)
    approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)
    if len(approx) > 6:
      (x,y), radius = cv2.minEnclosingCircle(cnt)
      center = (int(x), int(y))
      radius = int(radius)
      contour_area = cv2.contourArea(cnt)
      bounding_box_area = (2 * radius) ** 2
      area_ratio = contour_area / bounding_box_area
      if 0.6 < area_ratio < 2.0 and radius > 25 and radius < 60:
        y1 = max(0, int(y - radius))
        y2 = min(image.shape[0], int(y + radius))
        x1 = max(0, int(x - radius))
        x2 = min(image.shape[1], int(x + radius))

        roi = image[y1:y2, x1:x2]
        roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        roi_edges = cv2.Canny(roi_gray, 50, 150)
        contours_1, _1 = cv2.findContours(roi_edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours_1:
          epsilon = 0.02 * cv2.arcLength(contour, True)
          approx_1 = cv2.approxPolyDP(contour, epsilon, True)
          if len(approx_1) == 4 and estimate_red_color(roi):
            cv2.rectangle(image, (int(x - radius), int(y - radius)), (int(x + radius), int(y + radius)), (0, 255, 0), 2)
            cv2.putText(image, "CAM DI NGUOC CHIEU", (int(x), int(y + radius)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

def detect_no_left(image):
  ''' Ham xac dinh bien bao cam re trai '''
  # Covert space color
  hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
  lower_red1 = np.array([0, 50, 50])
  upper_red1 = np.array([10, 255, 255])
  mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
  lower_red2 = np.array([170, 50, 50])
  upper_red2 = np.array([180, 255, 255])
  mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
  mask_red = mask1 + mask2
  lower_white = np.array([0, 0, 200])
  upper_white = np.array([180, 30, 255])
  mask_white = cv2.inRange(hsv, lower_white, upper_white)
  mask = cv2.bitwise_or(mask_red, mask_white)
  blur = cv2.GaussianBlur(mask, (5, 5), 0)
  # Detect edges
  edges = cv2.Canny(blur, 50, 150)
  contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

  for cnt in contours:
    peri = cv2.arcLength(cnt, True)
    approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)
    if len(approx) > 6:
      (x,y), radius = cv2.minEnclosingCircle(cnt)
      center = (int(x), int(y))
      radius = int(radius)
      contour_area = cv2.contourArea(cnt)
      bounding_box_area = (2 * radius) ** 2
      area_ratio = contour_area / bounding_box_area
      if 0.6 < area_ratio < 2.0 and radius > 25 and radius < 60:
        y1 = max(0, int(y - radius))
        y2 = min(image.shape[0], int(y + radius))
        x1 = max(0, int(x - radius))
        x2 = min(image.shape[1], int(x + radius))

        roi = image[y1:y2, x1:x2]
        roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        roi_gray = cv2.GaussianBlur(roi_gray, (5, 5), 0)
        roi_edges = cv2.Canny(roi_gray, 50, 150)
        contours_1, _1 = cv2.findContours(roi_edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours_1:
          epsilon = 0.02 * cv2.arcLength(contour, True)
          approx_1 = cv2.approxPolyDP(contour, epsilon, True)
          if len(approx_1) > 8 :
            lines = cv2.HoughLines(roi_edges, 1, np.pi / 180, 50)
            if lines is not None:
              for line in lines:
                rho, theta = line[0]
                a = np.cos(theta)
                b = np.sin(theta)
                x0 = a * rho
                y0 = b * rho
                x1 = int(x0 + 1000 * (-b))
                y1 = int(y0 + 1000 * a)
                x2 = int(x0 - 1000 * (-b))
                y2 = int(y0 - 1000 * a)
                if abs((y2 - y1) / (x2 - x1 + 1e-6)) >= 1 and estimate_red_color(roi) == False:
                  cv2.rectangle(image, (int(x - radius), int(y - radius)), (int(x + radius), int(y + radius)), (0, 255, 0), 2)
                  cv2.putText(image, "CAM RE TRAI", (int(x), int(y + radius)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)


def detect_no_parking(img):
  ''' Ham xac dinh bien bao cam do xe'''

  hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    # Define red color range and create masks
  lower_red1 = np.array([0, 50, 50])
  upper_red1 = np.array([10, 255, 255])
  mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
  lower_red2 = np.array([170, 50, 50])
  upper_red2 = np.array([180, 255, 255])
  mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
  red_mask = mask1 | mask2

    # Apply mask to extract red regions
  red_regions = cv2.bitwise_and(img, img, mask=red_mask)

    # Convert to grayscale and detect edges
  gray = cv2.cvtColor(red_regions, cv2.COLOR_BGR2GRAY)
  blurred = cv2.GaussianBlur(gray, (5, 5), 0)
  edges = cv2.Canny(blurred, 50, 150)

    # Detect circular shapes using Hough Circle Transform
  circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, dp=1.2, minDist=50,
                                param1=50, param2=30, minRadius=20, maxRadius=100)
  if circles is not None:
    circles = np.uint16(np.around(circles))
    for circle in circles[0, :]:
      x, y, r = circle
      x, y, r = x.astype(np.int32), y.astype(np.int32), r.astype(np.int32)

      # Bound checks for slicing
      y1 = max(0, y - r)
      y2 = min(img.shape[0], y + r)
      x1 = max(0, x - r)
      x2 = min(img.shape[1], x + r)

      # Extract ROI
      roi = img[y1:y2, x1:x2]
      if roi.size == 0:
        continue
      roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
      roi_edges = cv2.Canny(roi_gray, 50, 150)
      lines = cv2.HoughLines(roi_edges, 1, np.pi/180, 30)
      if lines is not None:
        diagonal_line_detected = False
        for a, b in lines[:, 0]:
          if 0.2 < b < 1.0 or 2.1 < b < 2.9:
            diagonal_line_detected = True
            break
        if diagonal_line_detected and estimate_color_keep_right(roi) == False:
          cv2.rectangle(img, (x - r, y - r), (x + r, y + r), (0, 255, 0), 2)
          cv2.putText(img, "CAM DO XE", (x - r, y - r - 10),
                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

def detect_pedestrian_sign(image):
  ''' Ham xac dinh bien bao canh bao co nguoi qua duong '''

  hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

  # Set up mask for traffic sign with red and blue color
  lower_red1 = np.array([0, 100, 100])
  upper_red1 = np.array([10, 255, 255])
  lower_red2 = np.array([160, 100, 100])
  upper_red2 = np.array([179, 255, 255])

  mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)
  mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)
  mask_red = cv2.bitwise_or(mask_red1, mask_red2)

  lower_yellow = np.array([20, 100, 100])
  upper_yellow = np.array([30, 255, 255])
  mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)

  mask = cv2.bitwise_or(mask_red, mask_yellow)
  # Using GaussianBlur to smooth image and noise reduction
  blur = cv2.GaussianBlur(mask, (5, 5), 0)

  # Detect edges and find contours
  edges = cv2.Canny(blur, 50, 150)
  contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)

  for cnt in contours:
    peri = cv2.arcLength(cnt, True)
    approx = cv2.approxPolyDP(cnt, 0.02*peri, True)
    area = cv2.contourArea(cnt)
    x, y, w, h = cv2.boundingRect(cnt)
    aspect_ratio = float(w)/h

    if len(approx) == 3 and area > 1000 and 0.8 <= aspect_ratio <= 1.2:
      roi = image[y:y+h, x:x+w]
      roi_edges = cv2.Canny(roi, 50, 150)
      roi_contours, _ = cv2.findContours(roi_edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)

      for c in roi_contours:
        area_c = cv2.contourArea(c)
        if area_c < 300:
          cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)
          cv2.putText(image, "CANH BAO CO NGUOI QUA DUONG", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

def detect_goslow_sign(image):
  ''' Ham xac dinh bien bao di cham '''
  hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

  # Set up mask for traffic sign with red and blue color
  lower_red1 = np.array([0, 100, 100])
  upper_red1 = np.array([10, 255, 255])
  lower_red2 = np.array([160, 100, 100])
  upper_red2 = np.array([179, 255, 255])

  mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)
  mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)
  mask_red = cv2.bitwise_or(mask_red1, mask_red2)

  lower_yellow = np.array([20, 100, 100])
  upper_yellow = np.array([30, 255, 255])
  mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)

  mask = cv2.bitwise_or(mask_red, mask_yellow)
  # Using GaussianBlur to smooth image and noise reduction
  blur = cv2.GaussianBlur(mask, (5, 5), 0)

  # Detect edges and find contours
  edges = cv2.Canny(blur, 50, 150)
  contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)

  for cnt in contours:
    peri = cv2.arcLength(cnt, True)
    approx = cv2.approxPolyDP(cnt, 0.02*peri, True)
    area = cv2.contourArea(cnt)
    x, y, w, h = cv2.boundingRect(cnt)
    aspect_ratio = float(w)/h

    if len(approx) == 3 and area > 1000 and 0.8 <= aspect_ratio <= 1.2:
      roi = image[y:y+h, x:x+w]
      roi_edges = cv2.Canny(roi, 50, 150)
      roi_contours, _ = cv2.findContours(roi_edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)

      for c in roi_contours:
        area_c = cv2.contourArea(c)
        if  100 < area_c < 1000:
          cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)
          cv2.putText(image, "DI CHAM", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

def process_video(input_path, output_path):

    # Initialize video capture and writer
    cap = cv2.VideoCapture(input_path)
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))

    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.putText(frame, '52100879', (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA, False)

        # Call func
        detect_keep_right(frame)
        detect_one_way(frame)
        detect_no_left(frame)
        detect_no_parking(frame)
        detect_goslow_sign(frame)
        detect_pedestrian_sign(frame)

        # Write the frame into the output file
        out.write(frame)

    # Release resources
    cap.release()
    out.release()

input_video1_path = 'video1.mp4'
output_video1_path = 'output1.mp4'
input_video2_path = 'video2.mp4'
output_video2_path = 'output2.mp4'
process_video(input_video1_path, output_video1_path)
process_video(input_video2_path, output_video2_path)